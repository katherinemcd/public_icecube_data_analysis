{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1563ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IceCube events: \t 665481\n",
      "Number of skypoints to calc: \t 648\n",
      "Using parallel, time passed was: \t 7.044117\n",
      "0) \t n_s = \t 0.000000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IceCubeAnalysis_energy as IceCubeAnalysis\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def main(icecube_file_name, background_file_name, output_file_names,\n",
    "         step_size=15, n_cpu=None):\n",
    "    \"\"\"\n",
    "    Performs the all-sky source search. The script breaks the sky into\n",
    "    a grid, with step between points defined by `step_size`. For each \n",
    "point,\n",
    "    we find the most likely value of astrophysical neutrinos from the\n",
    "    source at the given point. Creates a map of the max-likelihood and\n",
    "    most-likely number of neutrinos from each point.\n",
    "    Parameters\n",
    "    ----------\n",
    "    icecube_file_name : str\n",
    "        IceCube pickle file location.\n",
    "    background_file_name : str\n",
    "        File location of pre-processed background PDF.\n",
    "    output_file_names : array_like\n",
    "        Outpnp.savez(\"./processed_data/background_energies_muon.npz\",\n",
    "        data_eng = data_eng,\n",
    "        data_dec = data_dec,\n",
    "        data_ra = data_ra)\n",
    "ut file names for fitted values of likelihood\n",
    "        (0th entry) and n_s (1st entry).\n",
    "    step_size : float\n",
    "        The degrees step size to perform the all-sky search.\n",
    "    n_cpu : int\n",
    "        The number of CPUs to use in the parallelization.\n",
    "        If n_cpu is None, the computation is not parallelized.\n",
    "    \"\"\"\n",
    "\n",
    "    use_parallel = (n_cpu is not None)\n",
    "\n",
    "    sourcesearch_ = IceCubeAnalysis.SourceSearch(icecube_file_name)\n",
    "    sourcesearch_.load_background(background_file_name)\n",
    "\n",
    "    #  This is the coordinate of each point on the sky we are checking.\n",
    "    cord_s, ra_len, dec_len = IceCubeAnalysis.prepare_skymap_coordinates(step_size)\n",
    "\n",
    "    N_sky_pts = len(cord_s)\n",
    "\n",
    "    print(\"Number of IceCube events: \\t %i\" % sourcesearch_.N)\n",
    "    print(\"Number of skypoints to calc: \\t %i\" % N_sky_pts)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        pool = Pool(n_cpu)\n",
    "\n",
    "        args_for_multiprocessing = [(np.array(cord_s[i_source]), i_source) for i_source in range(N_sky_pts)]\n",
    "        results = pool.starmap(sourcesearch_.job_submission,\n",
    "                               args_for_multiprocessing)\n",
    "\n",
    "        pool.close()\n",
    "    else:\n",
    "        results = []\n",
    "        for i_source in range(N_sky_pts):\n",
    "            results += [sourcesearch_.job_submission(cord_s[i_source],\n",
    "                                                     i_source)]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        print(\"Using parallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "    else:\n",
    "        print(\"Using nonparallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "\n",
    "    results_ = [list(t) for t in zip(*results)]\n",
    "    ns = results_[0]\n",
    "    del_ln_L = results_[1]\n",
    "    #eng_prob = np.array(results_[2])\n",
    "    #print(np.average(eng_prob).flatten())\n",
    "    n_s_map = np.reshape(ns, (ra_len, dec_len))\n",
    "    data_map = np.reshape(del_ln_L, (ra_len, dec_len))\n",
    "    np.save(output_file_names[0], data_map)\n",
    "    np.save(output_file_names[1], n_s_map)\n",
    "\n",
    "\n",
    "if(__name__ == \"__main__\"):\n",
    "    icecube_file_name = \"./processed_data/output_icecube_data_energy.npz\"\n",
    "    background_file_name = \"./processed_data/output_icecube_background_count_energy.npz\"\n",
    "    output_file_names = [\"./processed_data/calculated_fit_likelihood_map_allsky_test.npy\",\n",
    "                         \"./processed_data/calculated_fit_ns_map_allsky_test.npy\"]\n",
    "    main(icecube_file_name, background_file_name, output_file_names, step_size=10, n_cpu=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904d5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 2)\n",
      "Largest TS: nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Improper input: func input vector length N=2 must not exceed func output vector length M=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 207\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    206\u001b[0m     fit_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./processed_data/calculated_fit_likelihood_map_allsky_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 207\u001b[0m     sqrt_ts, ra, dec, ns \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 67\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(fit_file_name, step_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m bins_to_fit \u001b[38;5;241m=\u001b[39m counts \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m bins_to_fit \u001b[38;5;241m=\u001b[39m bins_to_fit \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m---> 67\u001b[0m popt, pcov \u001b[38;5;241m=\u001b[39m \u001b[43mcurve_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_gaus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbin_centers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbins_to_fit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbins_to_fit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m counts_with, bin_edges_with \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(sqrt_ts\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m     72\u001b[0m                                  \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m6\u001b[39m),\n\u001b[1;32m     73\u001b[0m                                  bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     74\u001b[0m bin_centers_with \u001b[38;5;241m=\u001b[39m (bin_edges_with[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m bin_edges_with[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/main/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:859\u001b[0m, in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ydata\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n \u001b[38;5;241m>\u001b[39m ydata\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of func parameters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m exceed the number of data points=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mydata\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 859\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mleastsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m popt, pcov, infodict, errmsg, ier \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    861\u001b[0m ysize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(infodict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfvec\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/main/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:417\u001b[0m, in \u001b[0;36mleastsq\u001b[0;34m(func, x0, args, Dfun, full_output, col_deriv, ftol, xtol, gtol, maxfev, epsfcn, factor, diag)\u001b[0m\n\u001b[1;32m    414\u001b[0m m \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m m:\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImproper input: func input vector length N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not exceed func output vector length M=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epsfcn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     epsfcn \u001b[38;5;241m=\u001b[39m finfo(dtype)\u001b[38;5;241m.\u001b[39meps\n",
      "\u001b[0;31mTypeError\u001b[0m: Improper input: func input vector length N=2 must not exceed func output vector length M=1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.optimize import curve_fit\n",
    "import IceCubeAnalysis_energy as IceCubeAnalysis\n",
    "#import IceCubeAnalysis\n",
    "\n",
    "def main(fit_file_name, step_size=2):\n",
    "    \"\"\"\n",
    "    Plots the results from the all-sky\n",
    "    best-fit source search.\n",
    "    Also prints out the most likely points on the sky.\n",
    "    Parameters\n",
    "    ----------\n",
    "    fit_file_name : str\n",
    "        Pickle file of the best-fit likelihood map.\n",
    "        \n",
    "    step_size : float\n",
    "        The degrees step size to perform the all-sky search.\n",
    "    \"\"\"\n",
    "\n",
    "    likelihood_map = np.load(fit_file_name,\n",
    "                             allow_pickle=True)\n",
    "    likelihood_map[likelihood_map <= 0.0] = 0.0\n",
    "    \n",
    "    ns_map = np.load(\"./processed_data/calculated_fit_ns_map_allsky_test.npy\", allow_pickle = True)\n",
    "    ns_map[ns_map<=0.0] = 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cord_s, ra_len, dec_len = IceCubeAnalysis.prepare_skymap_coordinates(step_size)\n",
    "    print(cord_s.shape)\n",
    "    every_pt = np.reshape(cord_s, (ra_len, dec_len, cord_s.shape[-1]))\n",
    "\n",
    "    sqrt_ts = np.sqrt(2.0 * likelihood_map)\n",
    "    sqrt_ts[np.abs(every_pt[:, :, 1]) > 87.0] = 0.0\n",
    "\n",
    "    print(\"Largest TS:\", np.max(sqrt_ts))\n",
    "\n",
    "    # Printout used to import table into Latex\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in index_of_best[:20]:\n",
    "        print(\"%.2f & %.2f & %.2f \\\\\\\\ \\hline\" % (sqrt_ts.flatten()[i],\n",
    "                                                  every_pt[:, :, 0].flatten()[i],\n",
    "                                                  every_pt[:, :, 1].flatten()[i]))\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ngc_1068 = np.logical_and(sqrt_ts.flatten()>=4.0, np.logical_and(every_pt[:, :, 0].flatten()>40, every_pt[:, :, 0].flatten()<42))\n",
    "    \n",
    "    counts, bin_edges = np.histogram(sqrt_ts.flatten()[np.logical_and(ngc_1068==False, ns_map.flatten() != 0)],\n",
    "                                     range=(0, 6),\n",
    "                                     bins=60)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n",
    "    index_of_best = np.argsort(-1 * sqrt_ts.flatten()[np.logical_and(ngc_1068==True, ns_map.flatten() != 0)])\n",
    "\n",
    "    # Fit the histogram with a gaussian.\n",
    "    def log_gaus(x, a, b):\n",
    "        return a + b * x * x \n",
    "\n",
    "    bins_to_fit = counts != 0\n",
    "    bins_to_fit = bins_to_fit >0.05\n",
    "\n",
    "    popt, pcov = curve_fit(log_gaus,\n",
    "                           bin_centers[bins_to_fit],\n",
    "                           np.log(counts[bins_to_fit]))\n",
    "\n",
    "    counts_with, bin_edges_with = np.histogram(sqrt_ts.flatten(),\n",
    "                                     range=(0, 6),\n",
    "                                     bins=60)\n",
    "    bin_centers_with = (bin_edges_with[:-1] + bin_edges_with[1:]) / 2.0\n",
    "\n",
    "    bins_to_fit_with = counts_with != 0\n",
    "    bins_to_fit_with = bins_to_fit_with >0.05\n",
    "\n",
    "    popt_with, pcov_with = curve_fit(log_gaus,\n",
    "                           bin_centers_with[bins_to_fit_with],\n",
    "                           np.log(counts_with[bins_to_fit_with]))\n",
    "\n",
    "    \n",
    "    \n",
    "    counts_ngc, bin_edges_ngc = np.histogram(sqrt_ts.flatten()[ngc_1068],\n",
    "                                     range=(0, 6),\n",
    "                                     bins=60)\n",
    "    bin_centers_ngc = (bin_edges_ngc[:-1] + bin_edges_ngc[1:]) / 2.0\n",
    "\n",
    "\n",
    "    chisq = np.sum((counts[bins_to_fit] - log_gaus(bin_centers[bins_to_fit], *popt))/np.sqrt(counts[bins_to_fit])**2)\n",
    "    \n",
    "    print(chisq/(len(counts[bins_to_fit])-1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    chisq_with = np.sum((counts_with[bins_to_fit_with] - log_gaus(bin_centers_with[bins_to_fit_with], *popt_with))/np.sqrt(counts_with[bins_to_fit_with])**2)\n",
    "    \n",
    "    print(chisq_with/(len(counts_with[bins_to_fit_with])-2))\n",
    "\n",
    "    ###90th percentile stuff \n",
    "    1.181033960775292\n",
    "    \n",
    "    for i in index_of_best[:20]:\n",
    "        print(\"%.2f & %.2f & %.2f \\\\\\\\ \\hline\" % (sqrt_ts.flatten()[np.logical_and(ngc_1068==True, ns_map.flatten() != 0)][i],\n",
    "                                                  every_pt[:, :, 0].flatten()[np.logical_and(ngc_1068==True, ns_map.flatten() != 0)][i],\n",
    "                                                  every_pt[:, :, 1].flatten()[np.logical_and(ngc_1068==True, ns_map.flatten() != 0)][i]))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    counts_90, bin_edges_90 = np.histogram(sqrt_ts.flatten(),\n",
    "                                     range=(0, 6),\n",
    "                                     bins=60)\n",
    "    bin_centers_90 = (bin_edges_90[:-1] + bin_edges_90[1:]) / 2.0\n",
    "\n",
    "    bins_to_fit_90 = counts_90 != 0\n",
    "    bin_centers_fit_90 = bin_centers_90[bins_to_fit_90]\n",
    "    counts_fit_90 = counts_90[bins_to_fit_90]\n",
    "    popt_90, pcov_90 = curve_fit(log_gaus,\n",
    "                           bin_centers_fit_90[bin_centers_fit_90<2],\n",
    "                           np.log(counts_fit_90[bin_centers_fit_90<2]))\n",
    "\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_yscale('log')\n",
    "    ax.errorbar(bin_centers, counts, xerr=3/len(counts), yerr=np.sqrt(counts),\n",
    "                color=\"black\", label=\"Observed (Northern Hemisphere)\", fmt='.')\n",
    "    \n",
    "    ax.errorbar(bin_centers_ngc, counts_ngc, xerr=3/len(counts_ngc), yerr=np.sqrt(counts_ngc),\n",
    "                color=\"black\", alpha = 0.5, label=\"NGC 1068\", fmt='.')\n",
    "\n",
    "    \n",
    "    \n",
    "    ax.plot(bin_centers, np.exp(log_gaus(bin_centers, *popt)),\n",
    "            color='blue', label=\"Normal Distribution\")\n",
    "    \n",
    "    ax.plot(bin_centers_with, np.exp(log_gaus(bin_centers_with, *popt_with)),\n",
    "            color='blue', alpha = 0.4, label=\"Normal Distribution with NGC 1068\")\n",
    "    \n",
    "    ax.set_ylim(0.5, 2.0 * counts[1])\n",
    "    ax.set_xlim(0.0, 6)\n",
    "    ax.set_xlabel(\"$\\sqrt{2 \\Delta \\ln \\mathcal{L}}$\", labelpad=10)\n",
    "    ax.set_ylabel(\"Number of sources\")\n",
    "    ax.grid()\n",
    "    ax.legend(fontsize = \"small\")\n",
    "    plt.tight_layout(pad=0.4, w_pad=1.0, h_pad=1.0)    \n",
    "    #plt.savefig(\"A03p2_fit_allsky_histogram.pdf\", dpi=300)\n",
    "    \"\"\"\n",
    "    np.savez(\"./plot_data/energy_distribution.npz\",\n",
    "            energy_dist_x = bin_centers,\n",
    "            energy_dist_y = counts)\n",
    "            \n",
    "    \"\"\"\n",
    "    plt.show()\n",
    "    \n",
    "    # Residual time\n",
    "    fig, ax = plt.subplots()\n",
    "    residual = counts - np.exp(log_gaus(bin_centers, *popt))\n",
    "    ax.errorbar(bin_centers, residual, xerr=3/len(counts), yerr=np.sqrt(counts),\n",
    "                color=\"black\", label=\"Observation\", fmt='.')\n",
    "    \n",
    "    ax.set_ylim(-50.0, 50.0)\n",
    "    ax.set_xlim(0.0, 6.0)\n",
    "    ax.set_xlabel(\"$\\sqrt{2 \\Delta \\ln \\mathcal{L}}$\")\n",
    "    ax.set_ylabel(\"Fit Residual: Data - Fit\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    #plt.savefig(\"A03p2_fit_allsky_histogram_res.png\", dpi=300)\n",
    "    \n",
    "    N = 256\n",
    "    vals = np.ones((N, 4))\n",
    "    vals[:, 0] = np.linspace(1, 0/256, N)\n",
    "    vals[:, 1] = np.linspace(1, 0/256, N)\n",
    "    vals[:, 2] = np.linspace(1, 100/256, N)\n",
    "    newcmp = ListedColormap(vals)\n",
    "    print(np.shape(every_pt[:, :, 0]),np.shape(every_pt[:, :, 1]), np.shape(sqrt_ts))\n",
    "    ax = plt.subplot(111, projection=\"aitoff\")\n",
    "    pcolormesh = ax.pcolormesh(np.deg2rad(every_pt[:, :, 0])-np.pi,\n",
    "                               np.deg2rad(every_pt[:, :, 1]),\n",
    "                               sqrt_ts,\n",
    "                               cmap=newcmp, vmin=0, vmax=6)\n",
    "    cbar = plt.colorbar(pcolormesh, orientation=\"horizontal\")\n",
    "    cbar.set_label(\"$\\sqrt{2 \\Delta \\ln \\mathcal{L}}$\")\n",
    "    ax.set_rasterized(True)\n",
    "    #plt.savefig(\"A03p2_fit_allsky_map_aitoff.pdf\", dpi=300)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(sqrt_ts.transpose(), axis=0),\n",
    "               cmap=newcmp, extent=(0, 360, -90, 90), vmin=0, vmax=6)\n",
    "    plt.xlabel(\"RA [$^\\circ$]\")\n",
    "    plt.ylabel(\"$\\delta$ [$^\\circ$]\")\n",
    "    cbar = plt.colorbar(orientation=\"horizontal\")\n",
    "    cbar.set_label(\"$\\sqrt{2 \\Delta \\ln \\mathcal{L}}$\")\n",
    "    #plt.savefig(\"A03p2_fit_allsky_map_cart_energy.pdf\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.scatter(every_pt[:,:,1],sqrt_ts)\n",
    "    plt.show()\n",
    "    \n",
    "    return sqrt_ts.flatten(), every_pt[:, :, 0].flatten(), every_pt[:, :, 1].flatten(), ns_map.flatten()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fit_file_name = \"./processed_data/calculated_fit_likelihood_map_allsky_test.npy\"\n",
    "    sqrt_ts, ra, dec, ns = main(fit_file_name, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff08156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
