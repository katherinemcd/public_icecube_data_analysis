{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import IceCubeAnalysis as IceCubeAnalysis\n",
    "\n",
    "\n",
    "def main(icecube_file_name, background_file_name, catalog_file_name, source_class_names,\n",
    "         alpha=2.0, weights_type='dist', n_cpu=20, var_index_cut=None):\n",
    "    \"\"\"\n",
    "    For points in the sky from the 4LAC catalog, the function scans\n",
    "    over the number of neutrinos in the data from the source class\n",
    "    and calculates the likelihood. The number of neutrinos associated\n",
    "    to each source in the source class is determined by a weighting,\n",
    "    which is described in more detail in the paper. If a statistically\n",
    "    significant number of tracks in the data are associated with this\n",
    "    source class, the resulting likelihood will peak above 3sigma.\n",
    "    Parameters\n",
    "    ----------\n",
    "    icecube_file_name : str\n",
    "        File location of pickled IceCube track data.\n",
    "    background_file_name : str\n",
    "        File location of pre-processed background PDF.\n",
    "    catalog_file_name : str\n",
    "        File location of pickled 4LAC catalog.\n",
    "    source_class_names : array_like\n",
    "        Names of source classes used in calculation.\n",
    "    alpha : float\n",
    "        Neutrino energy spectrum integrated with the effective area.\n",
    "    weights_type : str\n",
    "        The weighting used for the source class. Options are 'flat' for\n",
    "        equal weight, 'flux' to weight against the gamma-ray flux, and\n",
    "        'dist' to weight against the luminosity distance.\n",
    "    n_cpu : int\n",
    "        The number of CPUs to use in the parallelization.\n",
    "        If n_cpu is None, the computation is not parallelized.\n",
    "    var_index_cut : float\n",
    "        Removes events that have a variability index greater\n",
    "        than var_index_cut. If None, no cut is performed.\n",
    "    Returns\n",
    "    ----------\n",
    "    sweep_flux : array\n",
    "        The array of fluxes of astrophysical neutrinos used\n",
    "        to calculate the likelihood of the source class\n",
    "        producing said astrophysical neutrino flux.\n",
    "    sweep_ts : array\n",
    "        The cumulative likelihood of the source class producing\n",
    "        the flux of astrophysical neutrinos.\n",
    "    sweep_ts_each_source : array\n",
    "        The likelihood of each individual source producing\n",
    "        the flux of astrophysical neutrinos.\n",
    "    \"\"\"\n",
    "\n",
    "    if(n_cpu is not None):\n",
    "        use_parallel = True\n",
    "    else:\n",
    "        use_parallel = False\n",
    "    \n",
    "    sourcesearch_ = IceCubeAnalysis.SourceSearch(icecube_file_name)\n",
    "    sourcesearch_.load_background(background_file_name)\n",
    "\n",
    "    # The time used in integration, in seconds\n",
    "    T = (10.0 * 365.25 * 24.0 * 3600.0)\n",
    "\n",
    "    # The energy bounds used in integration.\n",
    "    E1 = 100.0\n",
    "    E2 = 30.0\n",
    "\n",
    "    Aeff_filename = \"./processed_data/output_icecube_AffIntegrated_%s.npz\" % alpha\n",
    "    class_search = IceCubeAnalysis.SourceClassSearch(T, E1, E2, alpha, sourcesearch_, Aeff_filename)\n",
    "\n",
    "\n",
    "    class_search.load_4lac(catalog_file_name, source_class_names, weights_type)\n",
    "\n",
    "    if(var_index_cut is not None):\n",
    "        class_search.var_index_cut(var_index_cut)\n",
    "\n",
    "    print(\"Number of Sources:\\t %i\" % class_search.N)\n",
    "    print(\"Number of Events:\\t %i\" % sourcesearch_.N)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        args_for_multiprocessing = np.arange(class_search.N)\n",
    "\n",
    "        pool = Pool(n_cpu)\n",
    "        parallel_results = pool.map(class_search.source_loop,\n",
    "                                    args_for_multiprocessing)\n",
    "        pool.close()\n",
    "\n",
    "        parallel_results = [list(t) for t in zip(*parallel_results)]\n",
    "\n",
    "        sweep_ts_each_source = np.stack(parallel_results[1], axis=1)\n",
    "        sweep_ts = np.sum(parallel_results[1], axis=0)\n",
    "        sweep_flux = np.sum(parallel_results[0], axis=0)\n",
    "    else:\n",
    "        # Calculate the points that we will then loop over\n",
    "        parameterized_span = class_search.calculate_span()\n",
    "\n",
    "        sweep_ts = np.zeros(len(parameterized_span))\n",
    "        sweep_flux = np.zeros(len(parameterized_span))\n",
    "        sweep_ts_each_source = np.zeros((len(parameterized_span), class_search.N))\n",
    "\n",
    "        for i_source in range(class_search.N):\n",
    "            sweep_fluxes_, ts_results_ = class_search.source_loop(i_source)\n",
    "\n",
    "            sweep_flux += sweep_fluxes_\n",
    "            sweep_ts += ts_results_\n",
    "            sweep_ts_each_source[:, i_source] = ts_results_\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        print(\"Using parallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "    else:\n",
    "        print(\"Using nonparallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "\n",
    "    sweep_flux *= 1000.0  # convert TeV to GeV\n",
    "\n",
    "        \n",
    "    return sweep_flux, sweep_ts, sweep_ts_each_source\n",
    "\n",
    "\n",
    "if(__name__ == \"__main__\"):\n",
    "\n",
    "    catalog_file_name = \"./processed_data/4LAC_catelogy.npz\"\n",
    "    icecube_file_name = \"./processed_data/output_icecube_data_energy.npz\"\n",
    "    background_file_name = \"./processed_data/output_icecube_background_count_energy.npz\"\n",
    "\n",
    "    output_file_preamble = ['nonblazar','blazar']\n",
    "    cut_type = ['Nocut','non_var']\n",
    "    blazar = ['BLL', 'bll', 'FSRQ', 'fsrq', 'BCU', 'bcu']\n",
    "    nonblazar = ['RDG', 'rdg', 'AGN', 'agn', 'NLSY1', 'nlsy1','CSS','css','SSRQ','ssrq','SEY','sey']\n",
    "    #very = ['BLL', 'bll', 'FSRQ', 'fsrq', 'BCU', 'bcu','RDG', 'rdg', 'AGN', 'agn', 'NLSY1', 'nlsy1','CSS','css','SSRQ','ssrq','SEY','sey']\n",
    "    source_class_names = [nonblazar,blazar]\n",
    "    \n",
    "    weights_types = ['flat', 'flux', 'dist']\n",
    "    #eights_types = ['inv_flux']\n",
    "    colors = ['orange', 'green', 'blue']\n",
    "    labels = ['Flat', r'$\\gamma$-Ray', r'1/D$_L^2$']\n",
    "    var_cut_types = [None, 18.48]\n",
    "\n",
    "    alphas = [2.0, 2.5]\n",
    "    linestyles = ['-', '--']\n",
    "\n",
    "    for i_source_class_names, source_class_name in enumerate(source_class_names):\n",
    "    \n",
    "        for i_var_cut_types, var_cut_type in enumerate(var_cut_types):\n",
    "\n",
    "            plt.figure(figsize=(5, 4))\n",
    "\n",
    "            for i_alpha, alpha in enumerate(alphas):\n",
    "\n",
    "                for i_weights_type, weights_type in enumerate(weights_types):\n",
    "                    sweep_flux, sweep_ts, sweep_ts_each_source = main(icecube_file_name=icecube_file_name,\n",
    "                                                                 background_file_name=background_file_name,\n",
    "                                                                 catalog_file_name=catalog_file_name,\n",
    "                                                                 source_class_names=source_class_name,\n",
    "                                                                 alpha=alpha,\n",
    "                                                                 weights_type=weights_type,\n",
    "                                                                 n_cpu=8,\n",
    "                                                                 var_index_cut=var_cut_type)\n",
    "\n",
    "                    np.savez(\"./processed_data/limit_analysis_data/output_analysis_%s_%s_alpha%.1f_%s_limit_energy.npz\" % (output_file_preamble[i_source_class_names], cut_type[i_var_cut_types], alpha, weights_type),\n",
    "                             flux_span=sweep_flux, results=sweep_ts)\n",
    "                    \n",
    "                    plt.semilogx(np.array(sweep_flux)[sweep_ts < 1e3],\n",
    "                                 sweep_ts[sweep_ts < 1e3],\n",
    "                                 linestyle=linestyles[i_alpha],\n",
    "                                 color=colors[i_weights_type])            \n",
    "                    \n",
    "\n",
    "            \n",
    "            for i_weights_type, weights_type in enumerate(weights_types):\n",
    "                plt.plot([], [], color=colors[i_weights_type], label=labels[i_weights_type])\n",
    "\n",
    "            for i_alpha, alpha in enumerate(alphas):\n",
    "                plt.plot([], [], color='black', linestyle=linestyles[i_alpha], label=r\"$\\alpha=$\" + str(alpha))\n",
    "\n",
    "            plt.axhline(-3.85,\n",
    "                        color=\"red\",\n",
    "                        linestyle=\"-.\",\n",
    "                        label=\"95% CL\")\n",
    "\n",
    "            plt.xlabel(r\"$E^2_\\nu dN_\\nu/dE_\\nu$ [GeV / cm$^2$ / s / sr] at 30 TeV\")\n",
    "            plt.ylabel(\"$2 \\Delta \\ln \\mathcal{L}$\")\n",
    "            plt.xlim(5e-10, 5e-7)\n",
    "            plt.ylim(-10.0, 4.0)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "\n",
    "            #plt.savefig(\"./plots/A05_analyze_source_classes_limits_%s_%s_cut.png\"%(output_file_preamble[i_source_class_names],cut_type[i_var_cut_types]), dpi=300)\n",
    "            print('%s agn, %s' % (output_file_preamble[i_source_class_names],cut_type[i_var_cut_types]))\n",
    "            plt.show()\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
