{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IceCubeAnalysis\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def main(icecube_file_name, background_file_name, output_file_names,\n",
    "         step_size=0.5, n_cpu=20):\n",
    "    \"\"\"\n",
    "    Performs the all-sky source search. The script breaks the sky into\n",
    "    a grid, with step between points defined by `step_size`. For each point,\n",
    "    we find the most likely value of astrophysical neutrinos from the\n",
    "    source at the given point. Creates a map of the max-likelihood and\n",
    "    most-likely number of neutrinos from each point.\n",
    "    Parameters\n",
    "    ----------\n",
    "    icecube_file_name : str\n",
    "        IceCube pickle file location.\n",
    "    background_file_name : str\n",
    "        File location of pre-processed background PDF.\n",
    "    output_file_names : array_like\n",
    "        Output file names for fitted values of likelihood\n",
    "        (0th entry) and n_s (1st entry).\n",
    "    step_size : float\n",
    "        The degrees step size to perform the all-sky search.\n",
    "    n_cpu : int\n",
    "        The number of CPUs to use in the parallelization.\n",
    "        If n_cpu is None, the computation is not parallelized.\n",
    "    \"\"\"\n",
    "\n",
    "    use_parallel = (n_cpu is not None)\n",
    "\n",
    "    sourcesearch_ = IceCubeAnalysis.SourceSearch(icecube_file_name)\n",
    "    sourcesearch_.load_background(background_file_name)\n",
    "\n",
    "    #  This is the coordinate of each point on the sky we are checking.\n",
    "    cord_s, ra_len, dec_len = IceCubeAnalysis.prepare_skymap_coordinates(step_size)\n",
    "\n",
    "    N_sky_pts = len(cord_s)\n",
    "\n",
    "    print(\"Number of IceCube events: \\t %i\" % sourcesearch_.N)\n",
    "    print(\"Number of skypoints to calc: \\t %i\" % N_sky_pts)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        pool = Pool(n_cpu)\n",
    "\n",
    "        args_for_multiprocessing = [(np.array(cord_s[i_source]), i_source) for i_source in range(N_sky_pts)]\n",
    "        results = pool.starmap(sourcesearch_.job_submission,\n",
    "                               args_for_multiprocessing)\n",
    "\n",
    "        pool.close()\n",
    "    else:\n",
    "        results = []\n",
    "        for i_source in range(N_sky_pts):\n",
    "            results += [sourcesearch_.job_submission(cord_s[i_source],\n",
    "                                                     i_source)]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    if(use_parallel):\n",
    "        print(\"Using parallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "    else:\n",
    "        print(\"Using nonparallel, time passed was: \\t %f\" % (end_time - start_time))\n",
    "\n",
    "    results_ = [list(t) for t in zip(*results)]\n",
    "    ns = results_[0]\n",
    "    del_ln_L = results_[1]\n",
    "\n",
    "    n_s_map = np.reshape(ns, (ra_len, dec_len))\n",
    "    data_map = np.reshape(del_ln_L, (ra_len, dec_len))\n",
    "\n",
    "    np.save(output_file_names[0], data_map)\n",
    "    np.save(output_file_names[1], n_s_map)\n",
    "\n",
    "\n",
    "if(__name__ == \"__main__\"):\n",
    "    icecube_file_name = \"./processed_data/output_icecube_data.npz\"\n",
    "    background_file_name = \"./processed_data/output_icecube_background_count.npz\"\n",
    "    output_file_names = [\"./processed_data/calculated_fit_likelihood_map_allsky.npy\",\n",
    "                         \"./processed_data/calculated_fit_ns_map_allsky.npy\"]\n",
    "    main(icecube_file_name, background_file_name, output_file_names, step_size=0.5, n_cpu=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
